epoch,learning_rate,step,train_loss_epoch,train_loss_step,val_acc,val_loss
0,,15,,,0.1875,2.2799072265625
0,1.8999999156221747e-05,15,2.27801513671875,,,
1,,31,,,0.1875,2.226318359375
1,1.8999999156221747e-05,31,2.2469024658203125,,,
2,,47,,,0.1875,2.2156982421875
2,1.8999999156221747e-05,47,2.2254714965820312,,,
3,,49,,2.1993408203125,,
3,,63,,,0.0625,2.227783203125
3,1.8999999156221747e-05,63,2.2028045654296875,,,
4,,79,,,0.0625,2.22406005859375
4,1.8999999156221747e-05,79,2.2237472534179688,,,
5,,95,,,0.0625,2.22320556640625
5,1.8999999156221747e-05,95,2.2280502319335938,,,
6,,99,,2.16510009765625,,
6,,111,,,0.0625,2.22161865234375
6,1.8999999156221747e-05,111,2.221038818359375,,,
7,,127,,,0.0625,2.212646484375
7,1.8999999156221747e-05,127,2.188892364501953,,,
8,,143,,,0.0625,2.2169189453125
8,1.8999999156221747e-05,143,2.218914031982422,,,
9,,149,,2.3843994140625,,
9,,159,,,0.0625,2.216552734375
9,1.8999999156221747e-05,159,2.2112960815429688,,,
10,,175,,,0.0625,2.2061767578125
10,1.7099999240599573e-05,175,2.2189788818359375,,,
11,,191,,,0.0625,2.20806884765625
11,1.7099999240599573e-05,191,2.201457977294922,,,
12,,199,,2.22100830078125,,
12,,207,,,0.0625,2.208251953125
12,1.7099999240599573e-05,207,2.2166900634765625,,,
