{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7824f7d8",
   "metadata": {},
   "source": [
    "# PyTorch 3D ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9ee457ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from sklearn.metrics import accuracy_score, r2_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "\n",
    "from models.ThreeDResNet import get_3dResNet, get_resnet_transformer\n",
    "from colorVideoDataset import ColorVideoDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c49168ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Arnav Waghdhare/.cache\\torch\\hub\\facebookresearch_pytorchvideo_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (blocks): ModuleList(\n",
      "    (0): ResNetBasicStem(\n",
      "      (conv): Conv3d(3, 64, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)\n",
      "      (norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU()\n",
      "      (pool): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=[0, 1, 1], dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (1): ResStage(\n",
      "      (res_blocks): ModuleList(\n",
      "        (0): ResBlock(\n",
      "          (branch1_conv): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(np.int64(1), np.int64(1), np.int64(1)), bias=False)\n",
      "          (branch1_norm): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (branch2): BottleneckBlock(\n",
      "            (conv_a): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (norm_a): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act_a): ReLU()\n",
      "            (conv_b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "            (norm_b): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act_b): ReLU()\n",
      "            (conv_c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (norm_c): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (1-2): 2 x ResBlock(\n",
      "          (branch2): BottleneckBlock(\n",
      "            (conv_a): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (norm_a): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act_a): ReLU()\n",
      "            (conv_b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "            (norm_b): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act_b): ReLU()\n",
      "            (conv_c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (norm_c): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): ResStage(\n",
      "      (res_blocks): ModuleList(\n",
      "        (0): ResBlock(\n",
      "          (branch1_conv): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(np.int64(1), np.int64(2), np.int64(2)), bias=False)\n",
      "          (branch1_norm): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (branch2): BottleneckBlock(\n",
      "            (conv_a): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (norm_a): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act_a): ReLU()\n",
      "            (conv_b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "            (norm_b): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act_b): ReLU()\n",
      "            (conv_c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (norm_c): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (1-3): 3 x ResBlock(\n",
      "          (branch2): BottleneckBlock(\n",
      "            (conv_a): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (norm_a): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act_a): ReLU()\n",
      "            (conv_b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "            (norm_b): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act_b): ReLU()\n",
      "            (conv_c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (norm_c): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): ResStage(\n",
      "      (res_blocks): ModuleList(\n",
      "        (0): ResBlock(\n",
      "          (branch1_conv): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(np.int64(1), np.int64(2), np.int64(2)), bias=False)\n",
      "          (branch1_norm): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (branch2): BottleneckBlock(\n",
      "            (conv_a): Conv3d(512, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "            (norm_a): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act_a): ReLU()\n",
      "            (conv_b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "            (norm_b): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act_b): ReLU()\n",
      "            (conv_c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (norm_c): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (1-5): 5 x ResBlock(\n",
      "          (branch2): BottleneckBlock(\n",
      "            (conv_a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "            (norm_a): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act_a): ReLU()\n",
      "            (conv_b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "            (norm_b): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act_b): ReLU()\n",
      "            (conv_c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (norm_c): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): ResStage(\n",
      "      (res_blocks): ModuleList(\n",
      "        (0): ResBlock(\n",
      "          (branch1_conv): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(np.int64(1), np.int64(2), np.int64(2)), bias=False)\n",
      "          (branch1_norm): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (branch2): BottleneckBlock(\n",
      "            (conv_a): Conv3d(1024, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "            (norm_a): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act_a): ReLU()\n",
      "            (conv_b): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "            (norm_b): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act_b): ReLU()\n",
      "            (conv_c): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (norm_c): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (1-2): 2 x ResBlock(\n",
      "          (branch2): BottleneckBlock(\n",
      "            (conv_a): Conv3d(2048, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "            (norm_a): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act_a): ReLU()\n",
      "            (conv_b): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "            (norm_b): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act_b): ReLU()\n",
      "            (conv_c): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "            (norm_c): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): ResNetBasicHead(\n",
      "      (pool): AvgPool3d(kernel_size=(8, 7, 7), stride=(1, 1, 1), padding=(0, 0, 0))\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "      (proj): Linear(in_features=2048, out_features=8, bias=True)\n",
      "      (output_pool): AdaptiveAvgPool3d(output_size=1)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "MODEL = get_3dResNet()\n",
    "DATASET = ColorVideoDataset('./colors')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097d56fe",
   "metadata": {},
   "source": [
    "Train, Test, Val Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd470b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = random_split(DATASET, [int(0.8 * len(DATASET)), len(DATASET) - int(0.8 * len(DATASET))])\n",
    "test_dataset, val_dataset = random_split(test_dataset, [int(0.5 * len(test_dataset)), len(test_dataset) - int(0.5 * len(test_dataset))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f516fe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(dataset, subset_ratio : float | None = 0.1, batch_size : int = 2):\n",
    "    transform = get_resnet_transformer()\n",
    "\n",
    "    def collate_fn(batch):\n",
    "        videos = []\n",
    "        labels = []\n",
    "        for video, label, _ in batch:\n",
    "            video = video.permute(1, 0, 2, 3)\n",
    "            video = transform({\"video\": video})[\"video\"]\n",
    "            videos.append(video)\n",
    "            labels.append(torch.tensor(label, dtype=torch.long))\n",
    "        \n",
    "        videos = torch.stack(videos)\n",
    "        labels = torch.stack(labels)\n",
    "        return videos, labels\n",
    "    \n",
    "    if subset_ratio is not None:\n",
    "        num_samples = int(len(dataset) * subset_ratio) \n",
    "        subset_indices = list(range(num_samples))\n",
    "        subset = Subset(dataset, subset_indices)\n",
    "        dataloader = DataLoader(subset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    else:\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad29a719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, dataloader, epochs=5, learning_rate=1e-4):\n",
    "    results_dict = {\n",
    "        'time_per_batch': [],\n",
    "        'time_per_epoch': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1': [],\n",
    "        'r2': [],\n",
    "        'loss': []\n",
    "    }\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(epochs), desc=\"Training Epochs\"):\n",
    "        running_loss = 0.0\n",
    "        epoch_start = time()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        for videos, labels in dataloader:\n",
    "            batch_start = time()\n",
    "            videos, labels = videos.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(videos)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            batch_time = time() - batch_start\n",
    "            results_dict['time_per_batch'].append(batch_time)\n",
    "            \n",
    "            # Store predictions and labels for metrics\n",
    "            all_preds.extend(outputs.argmax(dim=1).cpu().detach().numpy())\n",
    "            all_labels.extend(labels.cpu().detach().numpy())\n",
    "        \n",
    "        epoch_time = time() - epoch_start\n",
    "        results_dict['time_per_epoch'].append(epoch_time)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        results_dict['accuracy'].append(accuracy_score(all_labels, all_preds))\n",
    "        results_dict['precision'].append(precision_score(all_labels, all_preds, average='weighted', zero_division=0))\n",
    "        results_dict['recall'].append(recall_score(all_labels, all_preds, average='weighted', zero_division=0))\n",
    "        results_dict['f1'].append(f1_score(all_labels, all_preds, average='weighted', zero_division=0))\n",
    "        results_dict['r2'].append(r2_score(all_labels, all_preds))\n",
    "        \n",
    "        avg_loss = running_loss / len(dataloader)\n",
    "        results_dict['loss'].append(avg_loss)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5073b2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 8, 256, 256]) torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "dataloader = get_dataloader(DATASET, subset_ratio=0.1, batch_size=16)\n",
    "x, y = next(iter(dataloader))\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "652b40bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  10%|█         | 1/10 [00:04<00:41,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.9398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  20%|██        | 2/10 [00:08<00:34,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 0.7308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  30%|███       | 3/10 [00:12<00:29,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 0.5720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  40%|████      | 4/10 [00:17<00:25,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 0.4330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  50%|█████     | 5/10 [00:21<00:21,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 0.3305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  60%|██████    | 6/10 [00:25<00:16,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 0.2482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  70%|███████   | 7/10 [00:29<00:12,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 0.1903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  80%|████████  | 8/10 [00:33<00:08,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 0.1524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  90%|█████████ | 9/10 [00:38<00:04,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 0.1173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 10/10 [00:42<00:00,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.0981\n",
      "{'time_per_batch': [0.7560360431671143, 0.43861937522888184, 0.39720797538757324, 0.3898773193359375, 0.3858981132507324, 0.39762234687805176, 0.45095157623291016, 0.3962078094482422, 0.3863823413848877, 0.4003894329071045, 0.40998196601867676, 0.4006505012512207, 0.3985769748687744, 0.48401641845703125, 0.4817013740539551, 0.40950942039489746, 0.39815568923950195, 0.4507427215576172, 0.4028947353363037, 0.3863494396209717], 'time_per_epoch': [4.5674028396606445, 4.117170810699463, 4.126593828201294, 4.222600698471069, 4.170922517776489, 4.164057493209839, 4.2260901927948, 4.3325722217559814, 4.21908164024353, 4.1101765632629395], 'accuracy': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'precision': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'recall': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'f1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'r2': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = training_loop(MODEL, dataloader, epochs=10, learning_rate=2e-4)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95223ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader =  get_dataloader(train_dataset, subset_ratio=None, batch_size=4)\n",
    "val_dataloader =  get_dataloader(val_dataset, subset_ratio=None, batch_size=4)\n",
    "test_dataloader =  get_dataloader(test_dataset, subset_ratio=None, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b38db4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time_per_batch': [0.7560360431671143,\n",
       "  0.43861937522888184,\n",
       "  0.39720797538757324,\n",
       "  0.3898773193359375,\n",
       "  0.3858981132507324,\n",
       "  0.39762234687805176,\n",
       "  0.45095157623291016,\n",
       "  0.3962078094482422,\n",
       "  0.3863823413848877,\n",
       "  0.4003894329071045,\n",
       "  0.40998196601867676,\n",
       "  0.4006505012512207,\n",
       "  0.3985769748687744,\n",
       "  0.48401641845703125,\n",
       "  0.4817013740539551,\n",
       "  0.40950942039489746,\n",
       "  0.39815568923950195,\n",
       "  0.4507427215576172,\n",
       "  0.4028947353363037,\n",
       "  0.3863494396209717],\n",
       " 'time_per_epoch': [4.5674028396606445,\n",
       "  4.117170810699463,\n",
       "  4.126593828201294,\n",
       "  4.222600698471069,\n",
       "  4.170922517776489,\n",
       "  4.164057493209839,\n",
       "  4.2260901927948,\n",
       "  4.3325722217559814,\n",
       "  4.21908164024353,\n",
       "  4.1101765632629395],\n",
       " 'accuracy': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
       " 'precision': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
       " 'recall': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
       " 'f1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
       " 'r2': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geture-research-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
