{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7824f7d8",
   "metadata": {},
   "source": [
    "# PyTorch 3D ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee457ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav Waghdhare\\Desktop\\Arnav20\\Coding\\Python\\geture_research_ml\\.venv\\Lib\\site-packages\\torchvision\\transforms\\_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Arnav Waghdhare\\Desktop\\Arnav20\\Coding\\Python\\geture_research_ml\\.venv\\Lib\\site-packages\\torchvision\\transforms\\_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "\n",
    "from models.ThreeDResNet import get_3dResNet, get_resnet_transformer\n",
    "from colorVideoDataset import ColorVideoDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbb3203",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = get_3dResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c49168ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = ColorVideoDataset('./colors')\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097d56fe",
   "metadata": {},
   "source": [
    "Train, Test, Val Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd470b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = random_split(DATASET, [int(0.8 * len(DATASET)), len(DATASET) - int(0.8 * len(DATASET))])\n",
    "test_dataset, val_dataset = random_split(test_dataset, [int(0.5 * len(test_dataset)), len(test_dataset) - int(0.5 * len(test_dataset))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e3a0cc",
   "metadata": {},
   "source": [
    "## Dataloader and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f516fe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(dataset, subset_ratio : float | None = 0.1, batch_size : int = 2):\n",
    "    transform = get_resnet_transformer()\n",
    "\n",
    "    def collate_fn(batch):\n",
    "        videos = []\n",
    "        labels = []\n",
    "        for video, label, _ in batch:\n",
    "            video = video.permute(1, 0, 2, 3)\n",
    "            video = transform({\"video\": video})[\"video\"]\n",
    "            videos.append(video)\n",
    "            labels.append(torch.tensor(label, dtype=torch.long))\n",
    "        \n",
    "        videos = torch.stack(videos)\n",
    "        labels = torch.stack(labels)\n",
    "        return videos, labels\n",
    "    \n",
    "    if subset_ratio is not None:\n",
    "        num_samples = int(len(dataset) * subset_ratio) \n",
    "        subset_indices = list(range(num_samples))\n",
    "        subset = Subset(dataset, subset_indices)\n",
    "        dataloader = DataLoader(subset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    else:\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58341e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_loop(model, dataloader, criterion = None) -> tuple:\n",
    "    if criterion is None:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    model.eval()\n",
    "    for videos, labels in dataloader:\n",
    "        videos, labels = videos.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        outputs = model(videos)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "        all_preds.extend(outputs.argmax(dim=1).cpu().detach().numpy())\n",
    "        all_labels.extend(labels.cpu().detach().numpy())\n",
    "        \n",
    "    val_accuracy = accuracy_score(all_preds, all_labels)\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "\n",
    "    return (val_accuracy, avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad29a719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, train_dataloader, val_dataloader: DataLoader | None = None, \n",
    "                  epochs=5, learning_rate=2e-4, early_stopping_patience=10,\n",
    "                  checkpoint_path='best_model_3DResNet.pth', lr_patience=2):\n",
    "\n",
    "    results_dict = {\n",
    "        'time_per_batch': [],\n",
    "        'time_per_epoch': [],\n",
    "        'train_accuracy': [],\n",
    "        'train_loss': [],\n",
    "        'val_accuracy': [],\n",
    "        'val_loss': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1': [],\n",
    "        'learning_rate': [],\n",
    "    }\n",
    "    \n",
    "    model = model.to(DEVICE)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # ReduceLROnPlateau - tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=2)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.1, patience=lr_patience, verbose=True, min_lr=1e-7\n",
    "    )\n",
    "    \n",
    "    # EarlyStopping - tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "    \n",
    "    epoch_pbar = tqdm(range(epochs), desc=\"Training Epochs\")\n",
    "\n",
    "    for epoch in epoch_pbar:\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        epoch_start = time()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        for videos, labels in train_dataloader:\n",
    "            videos, labels = videos.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(videos)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            all_preds.extend(outputs.argmax(dim=1).cpu().detach().numpy())\n",
    "            all_labels.extend(labels.cpu().detach().numpy())\n",
    "        \n",
    "        epoch_time = time() - epoch_start\n",
    "        results_dict['time_per_epoch'].append(epoch_time)\n",
    "        \n",
    "        # MetricsCallback - tracks precision, recall, f1\n",
    "        results_dict['train_accuracy'].append(accuracy_score(all_labels, all_preds))\n",
    "        results_dict['precision'].append(precision_score(all_labels, all_preds, average='weighted', zero_division=0))\n",
    "        results_dict['recall'].append(recall_score(all_labels, all_preds, average='weighted', zero_division=0))\n",
    "        results_dict['f1'].append(f1_score(all_labels, all_preds, average='weighted', zero_division=0))\n",
    "        \n",
    "        avg_train_loss = running_loss / len(train_dataloader)\n",
    "        results_dict['train_loss'].append(avg_train_loss)\n",
    "        \n",
    "        val_accuracy, val_loss = infer_loop(model, val_dataloader, criterion)\n",
    "        \n",
    "        results_dict['val_accuracy'].append(val_accuracy)\n",
    "        results_dict['val_loss'].append(val_loss)\n",
    "        results_dict['learning_rate'].append(optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        # ReduceLROnPlateau callback\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # ModelCheckpoint - tf.keras.callbacks.ModelCheckpoint('best_model_TVN.h5', monitor='val_loss', save_best_only=True)\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_without_improvement = 0\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            epoch_pbar.write(f\"✓ Epoch {epoch+1}: Saved best model with val_loss: {val_loss:.4f}\")\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "        \n",
    "        # Update progress bar\n",
    "        epoch_pbar.set_postfix({\n",
    "            'train_loss': f\"{avg_train_loss:.4f}\",\n",
    "            'val_loss': f\"{val_loss:.4f}\",\n",
    "            'val_acc': f\"{val_accuracy:.4f}\",\n",
    "            'lr': f\"{optimizer.param_groups[0]['lr']:.2e}\"\n",
    "        })\n",
    "        \n",
    "        # EarlyStopping check\n",
    "        if epochs_without_improvement >= early_stopping_patience:\n",
    "            epoch_pbar.write(f\"\\n⚠ Early stopping triggered after {epoch + 1} epochs\")\n",
    "            break\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    epoch_pbar.write(f\"\\n✓ Loaded best model from {checkpoint_path}\")\n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5073b2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = get_dataloader(DATASET, subset_ratio=0.1, batch_size=16)\n",
    "x, y = next(iter(dataloader))\n",
    "print(x.shape, y.shape)\n",
    "del x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95223ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader =  get_dataloader(train_dataset, subset_ratio=None, batch_size=16)\n",
    "val_dataloader =  get_dataloader(val_dataset, subset_ratio=None, batch_size=16)\n",
    "test_dataloader =  get_dataloader(test_dataset, subset_ratio=None, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950a57a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = training_loop(\n",
    "    MODEL, \n",
    "    train_dataloader, \n",
    "    val_dataloader, \n",
    "    epochs=100, \n",
    "    learning_rate=2e-4,\n",
    "    early_stopping_patience=10,              \n",
    "    checkpoint_path='best_model_3DResNet.pth',  \n",
    "    lr_patience=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe37e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = './models/trained/3dResnet_Trained.pth'\n",
    "torch.save(MODEL.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f53d2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame.from_dict(results, orient=\"index\").T\n",
    "results_df.to_csv(\"3D_ResNet_Results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dc20aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(model_save_path)\n",
    "\n",
    "model.eval()\n",
    "test_acc, test_loss = infer_loop(model, test_loader)\n",
    "test_acc, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dc92cc",
   "metadata": {},
   "source": [
    "# TensorFlow TinyVideoNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87e7c33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav Waghdhare\\Desktop\\Arnav20\\Coding\\Python\\geture_research_ml\\.venv\\Lib\\site-packages\\tensorflow_hub\\__init__.py:61: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Arnav Waghdhare\\Desktop\\Arnav20\\Coding\\Python\\geture_research_ml\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Arnav Waghdhare\\Desktop\\Arnav20\\Coding\\Python\\geture_research_ml\\models\\TinyVideoNet.py:7: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as k\n",
    "import numpy as np\n",
    "from models.TinyVideoNet import TinyVideoNetTransfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41af0d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_data_generator(torch_dataset):\n",
    "    def generator():\n",
    "        for i in range(len(torch_dataset)):\n",
    "            video, label, _ = torch_dataset[i]\n",
    "            yield video, label\n",
    "    return generator\n",
    "\n",
    "def create_dataset(torch_ds, batch_size=4):\n",
    "    ds = tf.data.Dataset.from_generator(\n",
    "        tf_data_generator(torch_ds),\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(30, 3, 480, 640), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(), dtype=tf.int64)\n",
    "        )\n",
    "    )\n",
    "    return ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ceb74c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF Datasets\n",
    "tf_train = create_dataset(train_dataset, batch_size=4)\n",
    "tf_val = create_dataset(val_dataset, batch_size=4)\n",
    "tf_test = create_dataset(test_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3130be0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(x, y, num_classes=8):\n",
    "    y_one_hot = tf.one_hot(y, depth=num_classes)\n",
    "    return x, y_one_hot\n",
    "\n",
    "tf_train = tf_train.map(lambda x, y: to_one_hot(x, y, 8))\n",
    "tf_val = tf_val.map(lambda x, y: to_one_hot(x, y, 8))\n",
    "tf_test = tf_test.map(lambda x, y: to_one_hot(x, y, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2618f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_handle = 'https://kaggle.com/models/google/tiny-video-net/frameworks/TensorFlow1/variations/tvn1/versions/1'\n",
    "tf_model = TinyVideoNetTransfer(model_handle, num_classes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae00aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: (4, 30, 3, 480, 640)\n",
      "y.shape: (4, 8)\n",
      "y.dtype: <dtype: 'float32'>\n",
      "Sample label: [0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(tf_train))\n",
    "print(\"x.shape:\", x.shape)  # Should be (B, 30, 3, 480, 640)\n",
    "print(\"y.shape:\", y.shape)  # Should be (B,)\n",
    "print(\"y.dtype:\", y.dtype)  # Should be int32 or int64\n",
    "print(\"Sample label:\", y[0].numpy())  # Should be integer in [0, 7]\n",
    "\n",
    "del x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed7f3988",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCallback(k.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.time_per_epoch = []  # Track epoch times\n",
    "        self.epoch_start_time = None\n",
    "        \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start_time = time()\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Calculate epoch time\n",
    "        epoch_time = time() - self.epoch_start_time\n",
    "        self.time_per_epoch.append(epoch_time)\n",
    "        logs['time_per_epoch'] = epoch_time\n",
    "\n",
    "# Create the callback\n",
    "metrics_callback = MetricsCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28483f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.compile(\n",
    "    optimizer=k.optimizers.Adam(learning_rate=2e-4), \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        k.metrics.Precision(),\n",
    "        k.metrics.Recall(), \n",
    "        k.metrics.F1Score(average='macro')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51aa8c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "      8/Unknown \u001b[1m8s\u001b[0m 859ms/step - accuracy: 0.3141 - f1_score: 0.1696 - loss: 2.4431 - precision: 0.1079 - recall: 0.0381   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arnav Waghdhare\\Desktop\\Arnav20\\Coding\\Python\\geture_research_ml\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.2812 - f1_score: 0.1873 - loss: 2.2561 - precision: 0.1250 - recall: 0.0312 - val_accuracy: 0.1875 - val_f1_score: 0.0691 - val_loss: 2.1706 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.0000e-04 - time_per_epoch: 15.1407\n",
      "Epoch 2/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.2500 - f1_score: 0.1849 - loss: 2.4227 - precision: 0.2857 - recall: 0.0625 - val_accuracy: 0.0938 - val_f1_score: 0.0460 - val_loss: 2.1545 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.0000e-04 - time_per_epoch: 13.6725\n",
      "Epoch 3/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.1875 - f1_score: 0.1184 - loss: 2.1613 - precision: 0.2222 - recall: 0.0625 - val_accuracy: 0.0938 - val_f1_score: 0.0420 - val_loss: 2.1684 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.0000e-04 - time_per_epoch: 14.0636\n",
      "Epoch 4/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.1562 - f1_score: 0.0994 - loss: 2.2509 - precision: 0.4286 - recall: 0.0938 - val_accuracy: 0.0938 - val_f1_score: 0.0455 - val_loss: 2.1158 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.0000e-04 - time_per_epoch: 13.2234\n",
      "Epoch 5/5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.2500 - f1_score: 0.1601 - loss: 2.0161 - precision: 0.3333 - recall: 0.0938 - val_accuracy: 0.0938 - val_f1_score: 0.0442 - val_loss: 2.2150 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.0000e-04 - time_per_epoch: 13.0330\n"
     ]
    }
   ],
   "source": [
    "history = tf_model.fit(\n",
    "    tf_test,\n",
    "    validation_data=tf_val_oh, \n",
    "    epochs=5, \n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10), \n",
    "        tf.keras.callbacks.ModelCheckpoint('./models/trained_models/TVN_best_model.weights.h5', monitor='val_loss', save_best_only=True, save_weights_only=True), \n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=2), \n",
    "        metrics_callback\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40c068f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.28125, 0.25, 0.1875, 0.15625, 0.25],\n",
       " 'f1_score': [0.18733972311019897,\n",
       "  0.18492060899734497,\n",
       "  0.11837119609117508,\n",
       "  0.09940474480390549,\n",
       "  0.16011902689933777],\n",
       " 'loss': [2.256065845489502,\n",
       "  2.422661066055298,\n",
       "  2.161315441131592,\n",
       "  2.2509493827819824,\n",
       "  2.0161006450653076],\n",
       " 'precision': [0.125,\n",
       "  0.2857142984867096,\n",
       "  0.2222222238779068,\n",
       "  0.4285714328289032,\n",
       "  0.3333333432674408],\n",
       " 'recall': [0.03125, 0.0625, 0.0625, 0.09375, 0.09375],\n",
       " 'val_accuracy': [0.1875, 0.09375, 0.09375, 0.09375, 0.09375],\n",
       " 'val_f1_score': [0.06905370205640793,\n",
       "  0.045955877751111984,\n",
       "  0.041958037763834,\n",
       "  0.045454539358615875,\n",
       "  0.04417292773723602],\n",
       " 'val_loss': [2.170637845993042,\n",
       "  2.1545023918151855,\n",
       "  2.168384075164795,\n",
       "  2.115834951400757,\n",
       "  2.214994192123413],\n",
       " 'val_precision': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " 'val_recall': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " 'learning_rate': [0.00019999999494757503,\n",
       "  0.00019999999494757503,\n",
       "  0.00019999999494757503,\n",
       "  0.00019999999494757503,\n",
       "  0.00019999999494757503],\n",
       " 'time_per_epoch': [15.140650987625122,\n",
       "  13.672520875930786,\n",
       "  14.063580513000488,\n",
       "  13.223387479782104,\n",
       "  13.03298544883728]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfff106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame.from_dict(history.history, orient=\"index\").T\n",
    "results_df.to_csv(\"TVN_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86d25261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>loss</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_f1_score</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>time_per_epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.28125</td>\n",
       "      <td>0.187340</td>\n",
       "      <td>2.256066</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.18750</td>\n",
       "      <td>0.069054</td>\n",
       "      <td>2.170638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>15.140651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.184921</td>\n",
       "      <td>2.422661</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.06250</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.045956</td>\n",
       "      <td>2.154502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>13.672521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.18750</td>\n",
       "      <td>0.118371</td>\n",
       "      <td>2.161315</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.06250</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.041958</td>\n",
       "      <td>2.168384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>14.063581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.15625</td>\n",
       "      <td>0.099405</td>\n",
       "      <td>2.250949</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>2.115835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>13.223387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.160119</td>\n",
       "      <td>2.016101</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.044173</td>\n",
       "      <td>2.214994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>13.032985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  f1_score      loss  precision   recall  val_accuracy  \\\n",
       "0   0.28125  0.187340  2.256066   0.125000  0.03125       0.18750   \n",
       "1   0.25000  0.184921  2.422661   0.285714  0.06250       0.09375   \n",
       "2   0.18750  0.118371  2.161315   0.222222  0.06250       0.09375   \n",
       "3   0.15625  0.099405  2.250949   0.428571  0.09375       0.09375   \n",
       "4   0.25000  0.160119  2.016101   0.333333  0.09375       0.09375   \n",
       "\n",
       "   val_f1_score  val_loss  val_precision  val_recall  learning_rate  \\\n",
       "0      0.069054  2.170638            0.0         0.0         0.0002   \n",
       "1      0.045956  2.154502            0.0         0.0         0.0002   \n",
       "2      0.041958  2.168384            0.0         0.0         0.0002   \n",
       "3      0.045455  2.115835            0.0         0.0         0.0002   \n",
       "4      0.044173  2.214994            0.0         0.0         0.0002   \n",
       "\n",
       "   time_per_epoch  \n",
       "0       15.140651  \n",
       "1       13.672521  \n",
       "2       14.063581  \n",
       "3       13.223387  \n",
       "4       13.032985  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
